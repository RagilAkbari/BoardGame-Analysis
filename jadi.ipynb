{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHnrKYMXVRVIE82761Y7G3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RagilAkbari/BoardGame-Analysis/blob/main/jadi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jpbOuavPX0g"
      },
      "source": [
        "\r\n",
        "import tensorflow\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from matplotlib import pyplot\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "import time"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Af7lZ63pP-G9",
        "outputId": "b3d04c29-c6fd-498a-8592-9df8d6e47d41"
      },
      "source": [
        "from google.colab import files #upload data\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58cc1d0b-86b7-49c1-901d-95a50985290f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58cc1d0b-86b7-49c1-901d-95a50985290f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving bgg_db2.csv to bgg_db2 (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmwlSZpNQlAN"
      },
      "source": [
        "import io\r\n",
        "data = pd.read_csv('bgg_db2.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "_qvBonjcQq9z",
        "outputId": "5ee39a68-0114-4d70-dfd0-5a680d95de57"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>names</th>\n",
              "      <th>category</th>\n",
              "      <th>min_players</th>\n",
              "      <th>max_players</th>\n",
              "      <th>min_time</th>\n",
              "      <th>max_time</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>year</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>geek_rating</th>\n",
              "      <th>num_votes</th>\n",
              "      <th>rank</th>\n",
              "      <th>owned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Die Macher</td>\n",
              "      <td>Economic, Negotiation, Political</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>1986</td>\n",
              "      <td>7.62437</td>\n",
              "      <td>7.15383</td>\n",
              "      <td>5001</td>\n",
              "      <td>255.0</td>\n",
              "      <td>6615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dragonmaster</td>\n",
              "      <td>Card Game, Fantasy</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>1981</td>\n",
              "      <td>6.61497</td>\n",
              "      <td>5.80921</td>\n",
              "      <td>540</td>\n",
              "      <td>3444.0</td>\n",
              "      <td>1224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Samurai</td>\n",
              "      <td>Abstract Strategy, Medieval</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>1998</td>\n",
              "      <td>7.44113</td>\n",
              "      <td>7.24689</td>\n",
              "      <td>14155</td>\n",
              "      <td>199.0</td>\n",
              "      <td>14500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Tal der Könige</td>\n",
              "      <td>Ancient</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>1992</td>\n",
              "      <td>6.60429</td>\n",
              "      <td>5.70264</td>\n",
              "      <td>331</td>\n",
              "      <td>4530.0</td>\n",
              "      <td>607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Acquire</td>\n",
              "      <td>Economic</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>1964</td>\n",
              "      <td>7.34541</td>\n",
              "      <td>7.16840</td>\n",
              "      <td>17672</td>\n",
              "      <td>247.0</td>\n",
              "      <td>22352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   game_id           names  ...    rank  owned\n",
              "0        1      Die Macher  ...   255.0   6615\n",
              "1        2    Dragonmaster  ...  3444.0   1224\n",
              "2        3         Samurai  ...   199.0  14500\n",
              "3        4  Tal der Könige  ...  4530.0    607\n",
              "4        5         Acquire  ...   247.0  22352\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhKNfUdt8D_m"
      },
      "source": [
        "Menghilangkan Data yang \"duplicate\", null / missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XP6ZaJs7yG-",
        "outputId": "3dfd604a-6d61-4fa2-f624-1bb3180e8083"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "game_id        116455\n",
              "names          116455\n",
              "category       114405\n",
              "min_players    116455\n",
              "max_players    116455\n",
              "min_time       116455\n",
              "max_time       116455\n",
              "avg_time       116455\n",
              "year           116455\n",
              "avg_rating     116455\n",
              "geek_rating    116455\n",
              "num_votes      116455\n",
              "rank            18789\n",
              "owned          116455\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMQ8g38c770q"
      },
      "source": [
        "data = data.drop_duplicates() #drop duplikasi"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFYlJ1X38UAD",
        "outputId": "379eaf2e-34e1-4957-ffea-26dbf712e69a"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "game_id        116455\n",
              "names          116455\n",
              "category       114405\n",
              "min_players    116455\n",
              "max_players    116455\n",
              "min_time       116455\n",
              "max_time       116455\n",
              "avg_time       116455\n",
              "year           116455\n",
              "avg_rating     116455\n",
              "geek_rating    116455\n",
              "num_votes      116455\n",
              "rank            18789\n",
              "owned          116455\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEOtmPGG8ZsB"
      },
      "source": [
        "data = data.dropna() #drop nilai Null"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XpF7Joy8g8K",
        "outputId": "2e98bb90-8a57-42c2-eeca-44298f353371"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "game_id        18580\n",
              "names          18580\n",
              "category       18580\n",
              "min_players    18580\n",
              "max_players    18580\n",
              "min_time       18580\n",
              "max_time       18580\n",
              "avg_time       18580\n",
              "year           18580\n",
              "avg_rating     18580\n",
              "geek_rating    18580\n",
              "num_votes      18580\n",
              "rank           18580\n",
              "owned          18580\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF9dGtPX8liq"
      },
      "source": [
        "Mengubah data Average Rating menjadi 2 macam saja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "R0hR34Vd80Jc",
        "outputId": "7ed16bd8-42e4-4f48-da0d-7279f769d8e7"
      },
      "source": [
        "#nilai rating dari 0-10, rating < 5 == 0, sisa 1. Sebagai pembatas rating tinggi dan rendah\r\n",
        "data['avg_rating'] = (data['avg_rating'] >= 5).astype(int)\r\n",
        "data.head() "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>names</th>\n",
              "      <th>category</th>\n",
              "      <th>min_players</th>\n",
              "      <th>max_players</th>\n",
              "      <th>min_time</th>\n",
              "      <th>max_time</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>year</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>geek_rating</th>\n",
              "      <th>num_votes</th>\n",
              "      <th>rank</th>\n",
              "      <th>owned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Die Macher</td>\n",
              "      <td>Economic, Negotiation, Political</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>7.15383</td>\n",
              "      <td>5001</td>\n",
              "      <td>255.0</td>\n",
              "      <td>6615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dragonmaster</td>\n",
              "      <td>Card Game, Fantasy</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>1981</td>\n",
              "      <td>1</td>\n",
              "      <td>5.80921</td>\n",
              "      <td>540</td>\n",
              "      <td>3444.0</td>\n",
              "      <td>1224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Samurai</td>\n",
              "      <td>Abstract Strategy, Medieval</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>7.24689</td>\n",
              "      <td>14155</td>\n",
              "      <td>199.0</td>\n",
              "      <td>14500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Tal der Könige</td>\n",
              "      <td>Ancient</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>1992</td>\n",
              "      <td>1</td>\n",
              "      <td>5.70264</td>\n",
              "      <td>331</td>\n",
              "      <td>4530.0</td>\n",
              "      <td>607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Acquire</td>\n",
              "      <td>Economic</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>1964</td>\n",
              "      <td>1</td>\n",
              "      <td>7.16840</td>\n",
              "      <td>17672</td>\n",
              "      <td>247.0</td>\n",
              "      <td>22352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   game_id           names  ...    rank  owned\n",
              "0        1      Die Macher  ...   255.0   6615\n",
              "1        2    Dragonmaster  ...  3444.0   1224\n",
              "2        3         Samurai  ...   199.0  14500\n",
              "3        4  Tal der Könige  ...  4530.0    607\n",
              "4        5         Acquire  ...   247.0  22352\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQDEFoc9NeS"
      },
      "source": [
        "feature_cols = ['min_players','max_players','year','geek_rating','num_votes','owned'] #Fitur2 yg digunakan\r\n",
        "X = data[feature_cols]\r\n",
        "y = data.avg_rating #target"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2xvI9Q-BZe"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Nt7gZxb6-MY2",
        "outputId": "66aaec53-9b8e-45c4-bb17-27060fd38b1c"
      },
      "source": [
        "X_train #cek data train"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_players</th>\n",
              "      <th>max_players</th>\n",
              "      <th>year</th>\n",
              "      <th>geek_rating</th>\n",
              "      <th>num_votes</th>\n",
              "      <th>owned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1986</td>\n",
              "      <td>7.15383</td>\n",
              "      <td>5001</td>\n",
              "      <td>6615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1981</td>\n",
              "      <td>5.80921</td>\n",
              "      <td>540</td>\n",
              "      <td>1224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1998</td>\n",
              "      <td>7.24689</td>\n",
              "      <td>14155</td>\n",
              "      <td>14500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1992</td>\n",
              "      <td>5.70264</td>\n",
              "      <td>331</td>\n",
              "      <td>607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1964</td>\n",
              "      <td>7.16840</td>\n",
              "      <td>17672</td>\n",
              "      <td>22352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71076</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.52734</td>\n",
              "      <td>66</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71079</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.59018</td>\n",
              "      <td>154</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71081</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.51934</td>\n",
              "      <td>34</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71084</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2015</td>\n",
              "      <td>5.66756</td>\n",
              "      <td>206</td>\n",
              "      <td>613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71086</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "      <td>5.73798</td>\n",
              "      <td>280</td>\n",
              "      <td>1405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13006 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       min_players  max_players  year  geek_rating  num_votes  owned\n",
              "0                3            5  1986      7.15383       5001   6615\n",
              "1                3            4  1981      5.80921        540   1224\n",
              "2                2            4  1998      7.24689      14155  14500\n",
              "3                2            4  1992      5.70264        331    607\n",
              "4                2            6  1964      7.16840      17672  22352\n",
              "...            ...          ...   ...          ...        ...    ...\n",
              "71076            1            4  2014      5.52734         66    198\n",
              "71079            1            1  2014      5.59018        154    400\n",
              "71081            3           16  2014      5.51934         34     82\n",
              "71084            2            2  2015      5.66756        206    613\n",
              "71086            2            3  2015      5.73798        280   1405\n",
              "\n",
              "[13006 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "vafSl_kN-Skq",
        "outputId": "aece5716-da07-427c-b0f3-dfb954725812"
      },
      "source": [
        "X_test #cek data test"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_players</th>\n",
              "      <th>max_players</th>\n",
              "      <th>year</th>\n",
              "      <th>geek_rating</th>\n",
              "      <th>num_votes</th>\n",
              "      <th>owned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71092</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.58744</td>\n",
              "      <td>277</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71094</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.64748</td>\n",
              "      <td>378</td>\n",
              "      <td>1327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71095</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>5.58204</td>\n",
              "      <td>89</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71096</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.60465</td>\n",
              "      <td>99</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71098</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2015</td>\n",
              "      <td>6.26338</td>\n",
              "      <td>650</td>\n",
              "      <td>2085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113339</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2020</td>\n",
              "      <td>5.60093</td>\n",
              "      <td>109</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114664</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2020</td>\n",
              "      <td>5.57559</td>\n",
              "      <td>47</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114802</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>5.53111</td>\n",
              "      <td>33</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114865</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>5.71095</td>\n",
              "      <td>123</td>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115788</th>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2020</td>\n",
              "      <td>5.64651</td>\n",
              "      <td>131</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        min_players  max_players  year  geek_rating  num_votes  owned\n",
              "71092             3           10  2014      5.58744        277    602\n",
              "71094             2            5  2014      5.64748        378   1327\n",
              "71095             2            2  2016      5.58204         89    236\n",
              "71096             2            2  2014      5.60465         99    349\n",
              "71098             2            2  2015      6.26338        650   2085\n",
              "...             ...          ...   ...          ...        ...    ...\n",
              "113339            2            6  2020      5.60093        109    185\n",
              "114664            2            5  2020      5.57559         47    187\n",
              "114802            1            4  2020      5.53111         33     27\n",
              "114865            3            7  2020      5.71095        123    434\n",
              "115788            1           99  2020      5.64651        131    248\n",
              "\n",
              "[5574 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBYXz7GK-W5b",
        "outputId": "3980f410-3f4c-4e16-8972-73da2e52a292"
      },
      "source": [
        "#model Sequential dengan 3 layer\r\n",
        "model=keras.models.Sequential([\r\n",
        "    keras.layers.Dense(64, input_dim = X_train.shape[1], activation='tanh'),  \r\n",
        "    keras.layers.Dropout(0.3),\r\n",
        "    \r\n",
        "    keras.layers.Dense(units=32, activation='tanh'), \r\n",
        "    keras.layers.Dropout(0.2),\r\n",
        "    \r\n",
        "    keras.layers.Dense(units=1, activation=\"sigmoid\"),\r\n",
        "],name=\"Initial_model\",)\r\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Initial_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,561\n",
            "Trainable params: 2,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU-FTTna-b4r"
      },
      "source": [
        "#up learning rate paling kecil\r\n",
        "learning_rate = 0.01\r\n",
        "optimizer = keras.optimizers.Adam(lr=learning_rate)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuh8VsvM-fiS"
      },
      "source": [
        "model.compile(optimizer=optimizer,\r\n",
        "            loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTR8TC37-ggm"
      },
      "source": [
        "#fungsi class untuk menghentikan training ketika epoch tidak ada perkembangan\r\n",
        "early_stopping_monitor = EarlyStopping( \r\n",
        "    monitor='val_loss',\r\n",
        "    min_delta=0,\r\n",
        "    patience=100,\r\n",
        "    verbose=0,\r\n",
        "    mode='auto',\r\n",
        "    baseline=None,\r\n",
        "    restore_best_weights=True\r\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1Ym_aV-jnZ",
        "outputId": "0ec8659f-8e90-421d-c5c5-cc009eb00beb"
      },
      "source": [
        "#proses training\r\n",
        "start = time.clock() \r\n",
        "history = model.fit(X_train, y_train, epochs=1000, batch_size=512, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping_monitor])\r\n",
        "end = time.clock()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.2927 - accuracy: 0.9098 - val_loss: 0.1360 - val_accuracy: 0.9824\n",
            "Epoch 2/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.9098 - val_loss: 0.1172 - val_accuracy: 0.9824\n",
            "Epoch 3/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2969 - accuracy: 0.9098 - val_loss: 0.1567 - val_accuracy: 0.9824\n",
            "Epoch 4/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1253 - val_accuracy: 0.9824\n",
            "Epoch 5/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1224 - val_accuracy: 0.9824\n",
            "Epoch 6/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1229 - val_accuracy: 0.9824\n",
            "Epoch 7/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1254 - val_accuracy: 0.9824\n",
            "Epoch 8/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.9098 - val_loss: 0.1372 - val_accuracy: 0.9824\n",
            "Epoch 9/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1257 - val_accuracy: 0.9824\n",
            "Epoch 10/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.9098 - val_loss: 0.1245 - val_accuracy: 0.9824\n",
            "Epoch 11/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.9098 - val_loss: 0.1201 - val_accuracy: 0.9824\n",
            "Epoch 12/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1369 - val_accuracy: 0.9824\n",
            "Epoch 13/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1291 - val_accuracy: 0.9824\n",
            "Epoch 14/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.9098 - val_loss: 0.1425 - val_accuracy: 0.9824\n",
            "Epoch 15/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9098 - val_loss: 0.1144 - val_accuracy: 0.9824\n",
            "Epoch 16/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9098 - val_loss: 0.1267 - val_accuracy: 0.9824\n",
            "Epoch 17/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.9098 - val_loss: 0.1272 - val_accuracy: 0.9824\n",
            "Epoch 18/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.9098 - val_loss: 0.1298 - val_accuracy: 0.9824\n",
            "Epoch 19/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.9098 - val_loss: 0.1360 - val_accuracy: 0.9824\n",
            "Epoch 20/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.9098 - val_loss: 0.1341 - val_accuracy: 0.9824\n",
            "Epoch 21/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1363 - val_accuracy: 0.9824\n",
            "Epoch 22/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.9098 - val_loss: 0.1248 - val_accuracy: 0.9824\n",
            "Epoch 23/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.9098 - val_loss: 0.1500 - val_accuracy: 0.9824\n",
            "Epoch 24/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.9098 - val_loss: 0.1317 - val_accuracy: 0.9824\n",
            "Epoch 25/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.9098 - val_loss: 0.1224 - val_accuracy: 0.9824\n",
            "Epoch 26/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2913 - accuracy: 0.9098 - val_loss: 0.1326 - val_accuracy: 0.9824\n",
            "Epoch 27/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.9098 - val_loss: 0.1345 - val_accuracy: 0.9824\n",
            "Epoch 28/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2912 - accuracy: 0.9098 - val_loss: 0.1203 - val_accuracy: 0.9824\n",
            "Epoch 29/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9098 - val_loss: 0.1410 - val_accuracy: 0.9824\n",
            "Epoch 30/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1158 - val_accuracy: 0.9824\n",
            "Epoch 31/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.9098 - val_loss: 0.1236 - val_accuracy: 0.9824\n",
            "Epoch 32/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.9098 - val_loss: 0.1200 - val_accuracy: 0.9824\n",
            "Epoch 33/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.9098 - val_loss: 0.1333 - val_accuracy: 0.9824\n",
            "Epoch 34/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.9098 - val_loss: 0.1281 - val_accuracy: 0.9824\n",
            "Epoch 35/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.9098 - val_loss: 0.1227 - val_accuracy: 0.9824\n",
            "Epoch 36/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.9098 - val_loss: 0.1311 - val_accuracy: 0.9824\n",
            "Epoch 37/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9098 - val_loss: 0.1274 - val_accuracy: 0.9824\n",
            "Epoch 38/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1313 - val_accuracy: 0.9824\n",
            "Epoch 39/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1288 - val_accuracy: 0.9824\n",
            "Epoch 40/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.9098 - val_loss: 0.1160 - val_accuracy: 0.9824\n",
            "Epoch 41/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2943 - accuracy: 0.9098 - val_loss: 0.1532 - val_accuracy: 0.9824\n",
            "Epoch 42/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1146 - val_accuracy: 0.9824\n",
            "Epoch 43/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.9098 - val_loss: 0.1421 - val_accuracy: 0.9824\n",
            "Epoch 44/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2947 - accuracy: 0.9098 - val_loss: 0.1314 - val_accuracy: 0.9824\n",
            "Epoch 45/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1195 - val_accuracy: 0.9824\n",
            "Epoch 46/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.9098 - val_loss: 0.1325 - val_accuracy: 0.9824\n",
            "Epoch 47/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.9098 - val_loss: 0.1377 - val_accuracy: 0.9824\n",
            "Epoch 48/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.9098 - val_loss: 0.1194 - val_accuracy: 0.9824\n",
            "Epoch 49/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1248 - val_accuracy: 0.9824\n",
            "Epoch 50/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.9098 - val_loss: 0.1207 - val_accuracy: 0.9824\n",
            "Epoch 51/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.9098 - val_loss: 0.1352 - val_accuracy: 0.9824\n",
            "Epoch 52/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.9098 - val_loss: 0.1183 - val_accuracy: 0.9824\n",
            "Epoch 53/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.9098 - val_loss: 0.1149 - val_accuracy: 0.9824\n",
            "Epoch 54/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.9098 - val_loss: 0.1269 - val_accuracy: 0.9824\n",
            "Epoch 55/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.9098 - val_loss: 0.1403 - val_accuracy: 0.9824\n",
            "Epoch 56/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.9098 - val_loss: 0.1240 - val_accuracy: 0.9824\n",
            "Epoch 57/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.9098 - val_loss: 0.1374 - val_accuracy: 0.9824\n",
            "Epoch 58/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.9098 - val_loss: 0.1122 - val_accuracy: 0.9824\n",
            "Epoch 59/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9098 - val_loss: 0.1280 - val_accuracy: 0.9824\n",
            "Epoch 60/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9098 - val_loss: 0.1215 - val_accuracy: 0.9824\n",
            "Epoch 61/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.9098 - val_loss: 0.1314 - val_accuracy: 0.9824\n",
            "Epoch 62/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1467 - val_accuracy: 0.9824\n",
            "Epoch 63/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.9098 - val_loss: 0.1268 - val_accuracy: 0.9824\n",
            "Epoch 64/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.9098 - val_loss: 0.1270 - val_accuracy: 0.9824\n",
            "Epoch 65/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.9098 - val_loss: 0.1415 - val_accuracy: 0.9824\n",
            "Epoch 66/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1207 - val_accuracy: 0.9824\n",
            "Epoch 67/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1344 - val_accuracy: 0.9824\n",
            "Epoch 68/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.9098 - val_loss: 0.1239 - val_accuracy: 0.9824\n",
            "Epoch 69/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9098 - val_loss: 0.1293 - val_accuracy: 0.9824\n",
            "Epoch 70/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9098 - val_loss: 0.1421 - val_accuracy: 0.9824\n",
            "Epoch 71/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9098 - val_loss: 0.1401 - val_accuracy: 0.9824\n",
            "Epoch 72/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.9098 - val_loss: 0.1348 - val_accuracy: 0.9824\n",
            "Epoch 73/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.9098 - val_loss: 0.1328 - val_accuracy: 0.9824\n",
            "Epoch 74/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1293 - val_accuracy: 0.9824\n",
            "Epoch 75/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.9098 - val_loss: 0.1452 - val_accuracy: 0.9824\n",
            "Epoch 76/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.9098 - val_loss: 0.1082 - val_accuracy: 0.9824\n",
            "Epoch 77/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.9098 - val_loss: 0.1324 - val_accuracy: 0.9824\n",
            "Epoch 78/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1262 - val_accuracy: 0.9824\n",
            "Epoch 79/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1259 - val_accuracy: 0.9824\n",
            "Epoch 80/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.9098 - val_loss: 0.1460 - val_accuracy: 0.9824\n",
            "Epoch 81/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1209 - val_accuracy: 0.9824\n",
            "Epoch 82/1000\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.2933 - accuracy: 0.9098 - val_loss: 0.1254 - val_accuracy: 0.9824\n",
            "Epoch 83/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1321 - val_accuracy: 0.9824\n",
            "Epoch 84/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.9098 - val_loss: 0.1451 - val_accuracy: 0.9824\n",
            "Epoch 85/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1393 - val_accuracy: 0.9824\n",
            "Epoch 86/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9098 - val_loss: 0.1387 - val_accuracy: 0.9824\n",
            "Epoch 87/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1398 - val_accuracy: 0.9824\n",
            "Epoch 88/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9098 - val_loss: 0.1295 - val_accuracy: 0.9824\n",
            "Epoch 89/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.9098 - val_loss: 0.1304 - val_accuracy: 0.9824\n",
            "Epoch 90/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.9098 - val_loss: 0.1386 - val_accuracy: 0.9824\n",
            "Epoch 91/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.9098 - val_loss: 0.1494 - val_accuracy: 0.9824\n",
            "Epoch 92/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.9098 - val_loss: 0.1238 - val_accuracy: 0.9824\n",
            "Epoch 93/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2913 - accuracy: 0.9098 - val_loss: 0.1293 - val_accuracy: 0.9824\n",
            "Epoch 94/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.9098 - val_loss: 0.1198 - val_accuracy: 0.9824\n",
            "Epoch 95/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1260 - val_accuracy: 0.9824\n",
            "Epoch 96/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.9098 - val_loss: 0.1396 - val_accuracy: 0.9824\n",
            "Epoch 97/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.9098 - val_loss: 0.1116 - val_accuracy: 0.9824\n",
            "Epoch 98/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9098 - val_loss: 0.1438 - val_accuracy: 0.9824\n",
            "Epoch 99/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1436 - val_accuracy: 0.9824\n",
            "Epoch 100/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.9098 - val_loss: 0.1272 - val_accuracy: 0.9824\n",
            "Epoch 101/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.9098 - val_loss: 0.1501 - val_accuracy: 0.9824\n",
            "Epoch 102/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.9098 - val_loss: 0.1171 - val_accuracy: 0.9824\n",
            "Epoch 103/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.9098 - val_loss: 0.1438 - val_accuracy: 0.9824\n",
            "Epoch 104/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.9098 - val_loss: 0.1242 - val_accuracy: 0.9824\n",
            "Epoch 105/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9098 - val_loss: 0.1228 - val_accuracy: 0.9824\n",
            "Epoch 106/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.9098 - val_loss: 0.1334 - val_accuracy: 0.9824\n",
            "Epoch 107/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1279 - val_accuracy: 0.9824\n",
            "Epoch 108/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1398 - val_accuracy: 0.9824\n",
            "Epoch 109/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.9098 - val_loss: 0.1303 - val_accuracy: 0.9824\n",
            "Epoch 110/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9098 - val_loss: 0.1202 - val_accuracy: 0.9824\n",
            "Epoch 111/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.9098 - val_loss: 0.1362 - val_accuracy: 0.9824\n",
            "Epoch 112/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.9098 - val_loss: 0.1472 - val_accuracy: 0.9824\n",
            "Epoch 113/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9098 - val_loss: 0.1209 - val_accuracy: 0.9824\n",
            "Epoch 114/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.9098 - val_loss: 0.1098 - val_accuracy: 0.9824\n",
            "Epoch 115/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.9098 - val_loss: 0.1244 - val_accuracy: 0.9824\n",
            "Epoch 116/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.9098 - val_loss: 0.1295 - val_accuracy: 0.9824\n",
            "Epoch 117/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.9098 - val_loss: 0.1434 - val_accuracy: 0.9824\n",
            "Epoch 118/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9098 - val_loss: 0.1347 - val_accuracy: 0.9824\n",
            "Epoch 119/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.9098 - val_loss: 0.1290 - val_accuracy: 0.9824\n",
            "Epoch 120/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.9098 - val_loss: 0.1316 - val_accuracy: 0.9824\n",
            "Epoch 121/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.9098 - val_loss: 0.1184 - val_accuracy: 0.9824\n",
            "Epoch 122/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.9098 - val_loss: 0.1195 - val_accuracy: 0.9824\n",
            "Epoch 123/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1293 - val_accuracy: 0.9824\n",
            "Epoch 124/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.9098 - val_loss: 0.1262 - val_accuracy: 0.9824\n",
            "Epoch 125/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2979 - accuracy: 0.9098 - val_loss: 0.1259 - val_accuracy: 0.9824\n",
            "Epoch 126/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.9098 - val_loss: 0.1333 - val_accuracy: 0.9824\n",
            "Epoch 127/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.9098 - val_loss: 0.1260 - val_accuracy: 0.9824\n",
            "Epoch 128/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2969 - accuracy: 0.9098 - val_loss: 0.1171 - val_accuracy: 0.9824\n",
            "Epoch 129/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.9098 - val_loss: 0.1234 - val_accuracy: 0.9824\n",
            "Epoch 130/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.9098 - val_loss: 0.1353 - val_accuracy: 0.9824\n",
            "Epoch 131/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.9098 - val_loss: 0.1258 - val_accuracy: 0.9824\n",
            "Epoch 132/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1297 - val_accuracy: 0.9824\n",
            "Epoch 133/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1288 - val_accuracy: 0.9824\n",
            "Epoch 134/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9098 - val_loss: 0.1180 - val_accuracy: 0.9824\n",
            "Epoch 135/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.9098 - val_loss: 0.1270 - val_accuracy: 0.9824\n",
            "Epoch 136/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1391 - val_accuracy: 0.9824\n",
            "Epoch 137/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.9098 - val_loss: 0.1293 - val_accuracy: 0.9824\n",
            "Epoch 138/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.9098 - val_loss: 0.1105 - val_accuracy: 0.9824\n",
            "Epoch 139/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.9098 - val_loss: 0.1233 - val_accuracy: 0.9824\n",
            "Epoch 140/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.9098 - val_loss: 0.1374 - val_accuracy: 0.9824\n",
            "Epoch 141/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.9098 - val_loss: 0.1332 - val_accuracy: 0.9824\n",
            "Epoch 142/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.9098 - val_loss: 0.1273 - val_accuracy: 0.9824\n",
            "Epoch 143/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.9098 - val_loss: 0.1316 - val_accuracy: 0.9824\n",
            "Epoch 144/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9098 - val_loss: 0.1266 - val_accuracy: 0.9824\n",
            "Epoch 145/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.9098 - val_loss: 0.1438 - val_accuracy: 0.9824\n",
            "Epoch 146/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.9098 - val_loss: 0.1307 - val_accuracy: 0.9824\n",
            "Epoch 147/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1642 - val_accuracy: 0.9824\n",
            "Epoch 148/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.9098 - val_loss: 0.1136 - val_accuracy: 0.9824\n",
            "Epoch 149/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1401 - val_accuracy: 0.9824\n",
            "Epoch 150/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9098 - val_loss: 0.1402 - val_accuracy: 0.9824\n",
            "Epoch 151/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1297 - val_accuracy: 0.9824\n",
            "Epoch 152/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9098 - val_loss: 0.1226 - val_accuracy: 0.9824\n",
            "Epoch 153/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9098 - val_loss: 0.1309 - val_accuracy: 0.9824\n",
            "Epoch 154/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.9098 - val_loss: 0.1307 - val_accuracy: 0.9824\n",
            "Epoch 155/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9098 - val_loss: 0.1134 - val_accuracy: 0.9824\n",
            "Epoch 156/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1365 - val_accuracy: 0.9824\n",
            "Epoch 157/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.9098 - val_loss: 0.1193 - val_accuracy: 0.9824\n",
            "Epoch 158/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9098 - val_loss: 0.1221 - val_accuracy: 0.9824\n",
            "Epoch 159/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.9098 - val_loss: 0.1371 - val_accuracy: 0.9824\n",
            "Epoch 160/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.9098 - val_loss: 0.1181 - val_accuracy: 0.9824\n",
            "Epoch 161/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.9098 - val_loss: 0.1365 - val_accuracy: 0.9824\n",
            "Epoch 162/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.9098 - val_loss: 0.1216 - val_accuracy: 0.9824\n",
            "Epoch 163/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.9098 - val_loss: 0.1294 - val_accuracy: 0.9824\n",
            "Epoch 164/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1472 - val_accuracy: 0.9824\n",
            "Epoch 165/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.9098 - val_loss: 0.1363 - val_accuracy: 0.9824\n",
            "Epoch 166/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.9098 - val_loss: 0.1219 - val_accuracy: 0.9824\n",
            "Epoch 167/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.9098 - val_loss: 0.1419 - val_accuracy: 0.9824\n",
            "Epoch 168/1000\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.2960 - accuracy: 0.9098 - val_loss: 0.1289 - val_accuracy: 0.9824\n",
            "Epoch 169/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.9098 - val_loss: 0.1262 - val_accuracy: 0.9824\n",
            "Epoch 170/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.9098 - val_loss: 0.1287 - val_accuracy: 0.9824\n",
            "Epoch 171/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9098 - val_loss: 0.1454 - val_accuracy: 0.9824\n",
            "Epoch 172/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.9098 - val_loss: 0.1170 - val_accuracy: 0.9824\n",
            "Epoch 173/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.9098 - val_loss: 0.1339 - val_accuracy: 0.9824\n",
            "Epoch 174/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9098 - val_loss: 0.1316 - val_accuracy: 0.9824\n",
            "Epoch 175/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9098 - val_loss: 0.1389 - val_accuracy: 0.9824\n",
            "Epoch 176/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.9098 - val_loss: 0.1371 - val_accuracy: 0.9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGU387Yg-3qI",
        "outputId": "7d5ed02b-14bc-4a90-f0b9-5b6a0ef1a15d"
      },
      "source": [
        "print(\"Train time: {} \".format(end-start)) #cek waktu run train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train time: 25.597061999999994 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weNnrboR_AR_",
        "outputId": "0c22ddf0-ff63-4dca-aa2f-b87747837b76"
      },
      "source": [
        "#cek akurasi antara X_test dan y_test\r\n",
        "model.evaluate(x=X_test,y=y_test) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175/175 [==============================] - 0s 878us/step - loss: 0.1082 - accuracy: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10824409872293472, 0.9824183583259583]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}